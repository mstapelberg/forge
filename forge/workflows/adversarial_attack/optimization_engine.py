#!/usr/bin/env python
# TODO on 2025-02-28
# TODO need to add metadata to the vasp jobs individually that was in the ase.info of the atoms object we wrote to
# TODO Also need to make sure the output from the aa optimization (including the trajectory) is saved to it's own folder in the aa_output
# subdirectory of the root aa directory
# TODO need to re-do the test so that it grabs 25 structures from the database at random, runs force variance ranking on them, and then does aa on the top 3
"""Script engine for running adversarial attack optimization on a batch of structures.

This script provides two main optimization engines:
1. Gradient-based adversarial attack optimization
2. Monte Carlo based adversarial attack optimization

It is typically invoked via a SLURM script generated by the workflow setup
and processes structures from a specified XYZ file.
"""

import argparse
import json
from pathlib import Path
import ase.io
import numpy as np
from monty.serialization import dumpfn
import sys # Added for exit

# Keep original imports for optimizers and db
# ... existing code ...
from forge.core.adversarial_attack import (
    GradientAdversarialOptimizer,
    AdversarialCalculator,
    DisplacementGenerator,
    AdversarialOptimizer
)
from forge.core.database import DatabaseManager


# --- run_gradient_aa_optimization function ---
# (Add detailed docstring)
def run_gradient_aa_optimization(
    xyz_file: str,
    output_dir: str,
    model_paths: list[str],
    learning_rate: float = 0.01,
    n_iterations: int = 60,
    min_distance: float = 1.5,
    include_probability: bool = False,
    temperature: float = 0.86, # Temp for probability weighting (eV)
    device: str = "cuda",
    use_autograd: bool = False, # This likely needs specific MACE versions/forks
    save_to_database: bool = True,
    database_id: int = None, # Specific parent ID if known
    config_type: str = "aa-gradient",
    debug: bool = False,
    save_trajectory: bool = True, # Added parameter
):
    """Run gradient-based adversarial attack optimization on structures in XYZ file.

    This function iterates through structures in an XYZ file, applying gradient
    ascent to maximize the variance of forces predicted by an ensemble of models.

    Args:
        xyz_file: Path to input XYZ file containing structures.
        output_dir: Directory to save optimization results (trajectories, summary).
        model_paths: List of paths to model files (.model).
        learning_rate: Learning rate for gradient ascent steps.
        n_iterations: Number of optimization iterations.
        min_distance: Minimum allowed distance between atoms (Ã…) during optimization.
        include_probability: Whether to include the Boltzmann probability term in the loss
                             function, biasing towards lower-energy high-variance structures.
                             Requires 'temperature'.
        temperature: Temperature (in eV) used for the probability weighting term.
        device: Device to run calculations on ('cpu' or 'cuda').
        use_autograd: Placeholder for potential future Hessian-based optimizations. Currently unused.
        save_to_database: Whether to save optimized structures to the forge database.
        database_id: Optional parent structure ID from the database. If provided when
                     saving, the new structure will be linked.
        config_type: Configuration type label assigned when saving to the database.
        debug: Whether to print detailed debug messages during optimization.
        save_trajectory: Whether to save the optimization trajectory XYZ file for each structure.
    """
    from forge.core.adversarial_attack import GradientAdversarialOptimizer # Keep local import

    output_path = Path(output_dir)
    results_path = output_path / "aa_results" # Standardized results subfolder
    results_path.mkdir(parents=True, exist_ok=True)

    # Initialize database connection if needed
    db_manager = DatabaseManager() if save_to_database else None

    # Load structures
    try:
        atoms_list = ase.io.read(xyz_file, ':')
        print(f"[INFO] Loaded {len(atoms_list)} structures from {xyz_file}")
    except FileNotFoundError:
        print(f"[ERROR] Input XYZ file not found: {xyz_file}")
        return [], [] # Return empty lists on failure
    except Exception as e:
        print(f"[ERROR] Failed to read XYZ file {xyz_file}: {e}")
        return [], []

    # --- Energy handling for probability term (remains unchanged) ---
    # ... existing code ...
    energy_list = []
    if include_probability:
        # Get energies from atoms.info if available
        for atoms in atoms_list:
            # ... existing code ...
        # If we couldn't get any energies, disable include_probability
        if not energy_list:
            print("[WARNING] No energies found for probability weighting. Disabling probability term.")
            include_probability = False

    # Initialize the gradient-based optimizer
    print(f"[INFO] Initializing Gradient Optimizer on device: {device}")
    optimizer = GradientAdversarialOptimizer(
        model_paths=model_paths,
        device=device,
        learning_rate=learning_rate, # Passed during optimize call now
        temperature=temperature,
        include_probability=include_probability,
        energy_list=energy_list if energy_list else None,
        debug=debug
    )

    # Run optimization for each structure
    all_results_summary = [] # Changed name for clarity
    added_structure_ids = []

    for i, atoms in enumerate(atoms_list):
        struct_name = atoms.info.get('structure_name', f'struct_{i}')
        initial_variance = atoms.info.get('initial_variance', None)
        structure_id = atoms.info.get('structure_id', database_id) # Use database_id as fallback

        print(f"\n[INFO] Optimizing structure: {struct_name} (Index: {i}, ID: {structure_id or 'N/A'})")
        if initial_variance:
            print(f"[INFO] Initial variance: {initial_variance:.6f}")

        # Define output directory for this specific structure's trajectory
        struct_traj_dir = results_path / f"{struct_name}_output"
        if save_trajectory:
             struct_traj_dir.mkdir(exist_ok=True)

        # Run optimization
        try:
            # Pass output_dir for trajectory saving inside optimize
            best_atoms, best_variance, loss_history = optimizer.optimize(
                atoms=atoms.copy(), # Use a copy
                n_iterations=n_iterations,
                min_distance=min_distance,
                output_dir=str(struct_traj_dir) if save_trajectory else None, # Pass dir only if saving
                save_trajectory=save_trajectory # Explicitly pass flag
            )
        # ... existing error handling ...
        except Exception as e:
            print(f"[ERROR] Optimization failed for structure {struct_name}: {e}")
            if debug:
                import traceback
                traceback.print_exc()
            all_results_summary.append({ # Add failure record
                'structure_name': struct_name,
                'structure_index': i,
                'input_structure_id': structure_id,
                'status': 'failed',
                'error': str(e)
            })
            continue # Skip to next structure

        # Save optimized structure to database
        new_structure_id = None
        if save_to_database and db_manager is not None:
            try:
                # Ensure metadata is preserved and enriched
                # Use calculated initial variance if not present in input
                calc_initial_variance = loss_history[0] if loss_history else None
                db_initial_variance = initial_variance if initial_variance is not None else calc_initial_variance

                best_atoms.info['initial_variance'] = db_initial_variance
                best_atoms.info['final_variance'] = best_variance
                best_atoms.info['optimization_method'] = 'gradient-based'
                # Preserve original name/ID if possible
                best_atoms.info['parent_structure_name'] = atoms.info.get('structure_name', struct_name)
                best_atoms.info['parent_structure_id'] = structure_id


                # Prepare metadata for database with explicit type conversion
                metadata = {
                    'config_type': config_type,
                    'initial_variance': float(db_initial_variance) if db_initial_variance is not None else None,
                    'final_variance': float(best_variance),
                    'learning_rate': float(learning_rate),
                    'n_iterations': int(n_iterations),
                    'min_distance': float(min_distance),
                    'include_probability': bool(include_probability),
                    'temperature': float(temperature), # Temp used for probability weighting
                    'optimization_method': 'gradient-based'
                }

                # Add parent structure ID if available and valid
                if structure_id is not None:
                    try:
                        parent_id = int(structure_id)
                        metadata['parent_structure_id'] = parent_id # Use standard key

                        # Also fetch parent metadata to preserve lineage information
                        parent_metadata = db_manager.get_structure_metadata(parent_id)
                        if parent_metadata:
                            if 'config_type' in parent_metadata:
                                metadata['parent_config_type'] = str(parent_metadata['config_type'])
                            # Add other relevant parent info if needed (e.g., composition)
                    except (ValueError, TypeError) as e:
                        print(f"[WARNING] Could not use structure_id {structure_id} as parent_id: {e}")

                # Debug metadata before database insertion
                if debug:
                    print("[DEBUG] Metadata for database insertion:")
                    for key, value in metadata.items():
                        print(f"  {key}: {value} ({type(value)})")

                # Add structure to database
                new_structure_id = db_manager.add_structure(
                    best_atoms, # The structure with highest variance
                    metadata=metadata
                )

                print(f"[INFO] Added optimized structure to database with ID: {new_structure_id}")
                added_structure_ids.append(new_structure_id)

            except Exception as e:
                print(f"[ERROR] Failed to add structure {struct_name} to database: {e}")
                if debug:
                     import traceback
                     traceback.print_exc()

        # Save final optimized structure to file (always do this)
        optimized_file = results_path / f"{struct_name}_optimized.xyz"
        ase.io.write(optimized_file, best_atoms, format="extxyz", write_results=False)
        print(f"[INFO] Saved final optimized structure: {optimized_file}")

        # Append to results summary
        calc_initial_variance = loss_history[0] if loss_history else None
        summary_initial_variance = initial_variance if initial_variance is not None else calc_initial_variance

        result_data = {
            'structure_name': struct_name,
            'structure_index': i,
            'input_structure_id': structure_id, # Original ID from input file/info
            'initial_variance': summary_initial_variance,
            'final_variance': best_variance,
            'loss_history': loss_history,
            'optimized_xyz_file': str(optimized_file.relative_to(output_path)),
            'trajectory_dir': str(struct_traj_dir.relative_to(output_path)) if save_trajectory else None,
            'status': 'success',
        }

        # Add database information if available
        if new_structure_id:
            result_data['database_id'] = new_structure_id # ID of the *newly added* structure

        all_results_summary.append(result_data)

    # Save overall summary JSON file
    summary_file = output_path / 'optimization_summary.json'
    summary_data = {
        'input_file': xyz_file,
        'parameters': {
            'method': 'gradient-based',
            'learning_rate': learning_rate,
            'n_iterations': n_iterations,
            'min_distance': min_distance,
            'include_probability': include_probability,
            'temperature': temperature,
            'device': device,
            'use_autograd': use_autograd, # Keep record of parameter passed
            'save_trajectory': save_trajectory,
        },
        'database_info': {
             'saved_to_database': save_to_database,
             'config_type': config_type if save_to_database else None,
             'added_structure_ids': added_structure_ids,
        },
        'results': all_results_summary # Use the more descriptive name
    }
    dumpfn(summary_data, summary_file, indent=2)
    print(f"[INFO] Optimization summary saved to: {summary_file}")

    return all_results_summary, added_structure_ids # Return summary list and DB IDs

# --- run_aa_optimization (Monte Carlo) function ---
# (Add detailed docstring)
def run_aa_optimization(
    xyz_file: str,
    output_dir: str,
    model_paths: list[str],
    temperature: float = 1200.0, # Temp for Metropolis acceptance (K)
    max_steps: int = 50,
    patience: int = 25,
    min_distance: float = 2.0,
    max_displacement: float = 0.1, # Added parameter
    mode: str = "all",
    device: str = "cuda",
    save_to_database: bool = False,
    database_id: int = None, # Specific parent ID if known
    config_type: str = "aa-monte-carlo",
    debug: bool = False, # Added debug flag consistency
    save_trajectory: bool = True, # Added parameter
):
    """Run Monte Carlo adversarial attack optimization on structures in XYZ file.

    This function iterates through structures in an XYZ file, applying random
    displacements accepted based on the Metropolis criterion applied to the
    force variance, aiming to maximize model disagreement.

    Args:
        xyz_file: Path to input XYZ file containing structures.
        output_dir: Directory to save optimization results (trajectories, summary).
        model_paths: List of paths to model files (.model).
        temperature: Temperature (in K) for the Metropolis acceptance criterion.
                     Higher temperatures allow accepting more variance decreases.
        max_steps: Maximum number of Monte Carlo steps (proposed moves).
        patience: Stop optimization if the maximum variance hasn't increased for
                  this many steps.
        min_distance: Minimum allowed distance between atoms (Ã…) after displacement.
        max_displacement: Maximum distance (Ã…) an atom can be moved in a single step.
        mode: Displacement mode: 'all' (move all atoms) or 'single' (move one atom).
        device: Device to run calculations on ('cpu' or 'cuda').
        save_to_database: Whether to save optimized structures to the forge database.
        database_id: Optional parent structure ID from the database. If provided when
                     saving, the new structure will be linked.
        config_type: Configuration type label assigned when saving to the database.
        debug: Whether to print detailed debug messages during optimization.
        save_trajectory: Whether to save the optimization trajectory XYZ file for each structure.
                         Note: The MC optimizer saves trajectory if output_dir is given.
    """
    output_path = Path(output_dir)
    results_path = output_path / "aa_results" # Standardized results subfolder
    results_path.mkdir(parents=True, exist_ok=True)

    # Initialize calculator, optimizer, and database connection
    print(f"[INFO] Initializing Adversarial Calculator on device: {device}")
    calculator = AdversarialCalculator(
        model_paths=model_paths,
        device=device
    )
    print(f"[INFO] Initializing Displacement Generator: min_dist={min_distance}, max_disp={max_displacement}")
    # Pass max_displacement to the generator
    displacement_gen = DisplacementGenerator(min_distance=min_distance, max_displacement=max_displacement)

    print("[INFO] Initializing Monte Carlo Optimizer")
    optimizer = AdversarialOptimizer(
        adversarial_calc=calculator,
        displacement_gen=displacement_gen,
        debug=debug # Pass debug flag
    )

    db_manager = DatabaseManager() if save_to_database else None

    # Load structures
    try:
        atoms_list = ase.io.read(xyz_file, ':')
        print(f"[INFO] Loaded {len(atoms_list)} structures from {xyz_file}")
    except FileNotFoundError:
        print(f"[ERROR] Input XYZ file not found: {xyz_file}")
        return [], []
    except Exception as e:
        print(f"[ERROR] Failed to read XYZ file {xyz_file}: {e}")
        return [], []

    # Run optimization for each structure
    all_results_summary = [] # Changed name
    added_structure_ids = []

    for i, atoms in enumerate(atoms_list):
        struct_name = atoms.info.get('structure_name', f'struct_{i}')
        initial_variance = atoms.info.get('initial_variance', None)
        structure_id = atoms.info.get('structure_id', database_id) # Use database_id as fallback

        print(f"\n[INFO] Optimizing structure: {struct_name} (Index: {i}, ID: {structure_id or 'N/A'})")
        if initial_variance:
            print(f"[INFO] Initial variance: {initial_variance:.6f}")

        # Define output directory for this specific structure's trajectory etc.
        # The optimizer internally uses this path to save trajectory and summary snippet
        struct_output_path = results_path / f"{struct_name}_output"
        struct_output_path.mkdir(exist_ok=True)

        # Run optimization
        try:
            # Pass output_dir to enable trajectory saving within optimizer
            # Also pass save_trajectory flag if optimizer supports it explicitly (check needed)
            # Current AdversarialOptimizer saves traj if output_dir is not None.
            # It also saves a summary snippet there.
            best_atoms, best_variance, accepted_moves, step_variances = optimizer.optimize(
                atoms=atoms.copy(), # Use a copy
                temperature=temperature,
                max_iterations=max_steps,
                patience=patience,
                mode=mode,
                output_dir=str(struct_output_path) if save_trajectory else None, # Pass dir only if saving
                # Add save_trajectory=save_trajectory if optimizer takes it
            )
            print(f"[INFO] Optimization complete. Final variance: {best_variance:.6f}, Accepted moves: {accepted_moves}")

        # ... existing error handling ...
        except Exception as e:
            print(f"[ERROR] Optimization failed for structure {struct_name}: {e}")
            if debug:
                import traceback
                traceback.print_exc()
            all_results_summary.append({ # Add failure record
                 'structure_name': struct_name,
                 'structure_index': i,
                 'input_structure_id': structure_id,
                 'status': 'failed',
                 'error': str(e)
             })
            continue # Skip to next structure


        # Save optimized structure to database
        new_structure_id = None
        if save_to_database and db_manager is not None:
            try:
                # Ensure metadata is preserved and enriched
                # Calculate initial variance if not provided
                forces = calculator.calculate_forces(atoms) # Need initial forces
                calc_initial_variance = float(np.mean(calculator.calculate_normalized_force_variance(forces)))
                db_initial_variance = initial_variance if initial_variance is not None else calc_initial_variance

                best_atoms.info['initial_variance'] = db_initial_variance
                best_atoms.info['final_variance'] = best_variance
                best_atoms.info['optimization_method'] = 'monte-carlo'
                best_atoms.info['parent_structure_name'] = atoms.info.get('structure_name', struct_name)
                best_atoms.info['parent_structure_id'] = structure_id
                best_atoms.info['accepted_moves'] = accepted_moves

                # Prepare metadata for database
                metadata = {
                    'config_type': config_type,
                    'initial_variance': float(db_initial_variance) if db_initial_variance is not None else None,
                    'final_variance': float(best_variance),
                    'temperature': float(temperature), # Temp used for Metropolis
                    'max_steps': int(max_steps),
                    'patience': int(patience),
                    'min_distance': float(min_distance),
                    'max_displacement': float(max_displacement),
                    'mode': mode,
                    'accepted_moves': accepted_moves,
                    'optimization_method': 'monte-carlo'
                    # Consider adding step_variances if useful and not too large
                }

                # Add parent structure ID if available and valid
                if structure_id is not None:
                    try:
                        parent_id = int(structure_id)
                        metadata['parent_structure_id'] = parent_id

                        # Also fetch parent metadata to preserve lineage information
                        parent_metadata = db_manager.get_structure_metadata(parent_id)
                        if parent_metadata:
                             if 'config_type' in parent_metadata:
                                 metadata['parent_config_type'] = str(parent_metadata['config_type'])
                    except (ValueError, TypeError) as e:
                        print(f"[WARNING] Could not use structure_id {structure_id} as parent_id: {e}")


                # Debug metadata before database insertion
                if debug:
                     print("[DEBUG] Metadata for database insertion:")
                     for key, value in metadata.items():
                         print(f"  {key}: {value} ({type(value)})")

                # Add structure to database
                new_structure_id = db_manager.add_structure(
                    best_atoms, # Structure with highest variance found
                    metadata=metadata
                )

                print(f"[INFO] Added optimized structure to database with ID: {new_structure_id}")
                added_structure_ids.append(new_structure_id)

            except Exception as e:
                print(f"[ERROR] Failed to add structure {struct_name} to database: {e}")
                if debug:
                    import traceback
                    traceback.print_exc()


        # Save final optimized structure to file (always do this)
        optimized_file = results_path / f"{struct_name}_optimized.xyz"
        ase.io.write(optimized_file, best_atoms, format="extxyz", write_results=False)
        print(f"[INFO] Saved final optimized structure: {optimized_file}")
        if save_trajectory:
             # Trajectory is saved by optimizer inside struct_output_path
             print(f"[INFO] Trajectory and step summary saved in: {struct_output_path}")


        # Append to results summary
        forces = calculator.calculate_forces(atoms) # Recalculate if needed
        calc_initial_variance = float(np.mean(calculator.calculate_normalized_force_variance(forces)))
        summary_initial_variance = initial_variance if initial_variance is not None else calc_initial_variance

        result_data = {
            'structure_name': struct_name,
            'structure_index': i,
            'input_structure_id': structure_id,
            'initial_variance': summary_initial_variance,
            'final_variance': best_variance,
            'accepted_moves': accepted_moves,
            'step_variances': step_variances, # Include variance history
            'optimized_xyz_file': str(optimized_file.relative_to(output_path)),
            'trajectory_dir': str(struct_output_path.relative_to(output_path)) if save_trajectory else None,
            'status': 'success',
        }

        # Add database information if available
        if new_structure_id:
            result_data['database_id'] = new_structure_id

        all_results_summary.append(result_data)

    # Save overall summary JSON file
    summary_file = output_path / 'optimization_summary.json'
    summary_data = {
        'input_file': xyz_file,
        'parameters': {
            'method': 'monte-carlo',
            'temperature': temperature, # Metropolis temperature
            'max_steps': max_steps,
            'patience': patience,
            'min_distance': min_distance,
            'max_displacement': max_displacement,
            'mode': mode,
            'device': device,
            'save_trajectory': save_trajectory,
        },
         'database_info': {
             'saved_to_database': save_to_database,
             'config_type': config_type if save_to_database else None,
             'added_structure_ids': added_structure_ids,
        },
        'results': all_results_summary
    }
    dumpfn(summary_data, summary_file, indent=2)
    print(f"[INFO] Optimization summary saved to: {summary_file}")

    return all_results_summary, added_structure_ids

# --- REMOVE VASP Job Creation ---
# def create_vasp_jobs_from_aa_results(...): # REMOVED
# ... function content removed ...

# --- Main execution block ---
def main():
    parser = argparse.ArgumentParser(
        description="Run adversarial attack optimization engine on structures from XYZ file."
    )
    # Positional arguments expected from SLURM script
    parser.add_argument(
        "xyz_file",
        help="Input XYZ file containing structures for this batch job."
    )
    parser.add_argument(
        "output_dir",
        help="Directory to save optimization results for this batch job."
    )
    # Model input
    parser.add_argument(
        "--model_dir",
        required=True,
        help="Directory containing MACE *.model files for the ensemble."
    )
    # Method selection
    parser.add_argument(
        "--gradient",
        action="store_true",
        help="Use gradient-based optimization instead of Monte Carlo."
    )

    # Common parameters
    parser.add_argument(
        "--device",
        choices=['cpu', 'cuda'],
        default='cuda',
        help="Device to run calculations on ('cpu' or 'cuda')."
    )
    parser.add_argument(
        "--min_distance",
        type=float,
        # Default depends on method, handle below
        help="Minimum allowed distance between atoms (Ã…)."
    )
    parser.add_argument(
        "--save_trajectory",
        action=argparse.BooleanOptionalAction, # Creates --save-trajectory/--no-save-trajectory
        default=True,
        help="Save the optimization trajectory."
    )
    parser.add_argument(
        "--debug",
        action="store_true",
        help="Enable detailed debug messages."
    )

    # Database parameters
    parser.add_argument(
        "--save_to_database",
        action="store_true",
        help="Save optimized structures to the forge database."
    )
    parser.add_argument(
        "--database_id",
        type=int,
        help="Optional parent structure ID from database for lineage tracking."
    )
    parser.add_argument(
        "--config_type",
        type=str,
        help="Configuration type label for database saving (defaults based on method)."
    )

    # Parameters for Gradient optimization
    parser.add_argument(
        "--learning_rate",
        type=float,
        default=0.01,
        help="Learning rate for gradient ascent (gradient mode)."
    )
    parser.add_argument(
        "--n_iterations",
        type=int,
        default=60,
        help="Number of optimization iterations (gradient mode)."
    )
    parser.add_argument(
        "--include_probability",
        action="store_true",
        help="Include probability term in adversarial loss (gradient mode)."
    )
    parser.add_argument(
        "--use_autograd", # Keep for consistency, even if unused for now
        action="store_true",
        help="Placeholder for Hessian-based gradient calculation."
    )
    # Temperature has different meanings, handle based on mode
    parser.add_argument(
        "--temperature",
        type=float,
        # Default depends on method, handle below
        help="Temperature for optimization: Metropolis (K) for MC, probability weighting (eV) for gradient."
    )


    # Parameters for Monte Carlo optimization
    parser.add_argument(
        "--max_steps",
        type=int,
        default=50,
        help="Maximum optimization steps per structure (MC mode)."
    )
    parser.add_argument(
        "--patience",
        type=int,
        default=25,
        help="Stop if no improvement after this many steps (MC mode)."
    )
    parser.add_argument(
        "--max_displacement", # Added
        type=float,
        default=0.1,
        help="Maximum distance an atom can be moved in a single step (Ã…) (MC mode)."
    )
    parser.add_argument(
        "--mode",
        choices=['all', 'single'],
        default='all',
        help="Atom displacement mode ('all' or 'single') (MC mode)."
    )


    args = parser.parse_args()

    # --- Get model paths ---
    model_dir_path = Path(args.model_dir)
    if not model_dir_path.is_dir():
        print(f"[ERROR] Model directory not found: {args.model_dir}")
        sys.exit(1)
    model_paths = [str(p) for p in model_dir_path.glob("*.model")]
    if not model_paths:
        print(f"[ERROR] No *.model files found in {args.model_dir}")
        sys.exit(1)
    print(f"[INFO] Using {len(model_paths)} models from {args.model_dir}")

    # --- Set method-specific defaults if not provided ---
    if args.gradient:
        min_distance = args.min_distance if args.min_distance is not None else 1.5
        temperature = args.temperature if args.temperature is not None else 0.86 # eV default for gradient probability
        config_type = args.config_type or "aa-gradient"
        method_name = "Gradient-Based"
    else: # Monte Carlo
        min_distance = args.min_distance if args.min_distance is not None else 2.0
        temperature = args.temperature if args.temperature is not None else 1200.0 # K default for MC Metropolis
        config_type = args.config_type or "aa-mc"
        method_name = "Monte Carlo"

    print(f"[INFO] Running {method_name} Adversarial Attack")
    print(f"[INFO] Input structures: {args.xyz_file}")
    print(f"[INFO] Output directory: {args.output_dir}")
    print(f"[INFO] Device: {args.device}, Min distance: {min_distance}")

    # --- Execute selected optimization method ---
    try:
        if args.gradient:
            run_gradient_aa_optimization(
                xyz_file=args.xyz_file,
                output_dir=args.output_dir,
                model_paths=model_paths,
                learning_rate=args.learning_rate,
                n_iterations=args.n_iterations,
                min_distance=min_distance,
                include_probability=args.include_probability,
                temperature=temperature, # eV
                device=args.device,
                use_autograd=args.use_autograd,
                save_to_database=args.save_to_database,
                database_id=args.database_id,
                config_type=config_type,
                debug=args.debug,
                save_trajectory=args.save_trajectory,
            )
        else: # Monte Carlo
            run_aa_optimization(
                xyz_file=args.xyz_file,
                output_dir=args.output_dir,
                model_paths=model_paths,
                temperature=temperature, # K
                max_steps=args.max_steps,
                patience=args.patience,
                min_distance=min_distance,
                max_displacement=args.max_displacement, # Pass this arg
                mode=args.mode,
                device=args.device,
                save_to_database=args.save_to_database,
                database_id=args.database_id,
                config_type=config_type,
                debug=args.debug,
                save_trajectory=args.save_trajectory,
            )
        print("[INFO] Optimization engine finished successfully.")

    except Exception as e:
        print(f"\n[ERROR] An critical error occurred during optimization: {e}")
        if args.debug:
            import traceback
            traceback.print_exc()
        sys.exit(1)


# --- REMOVE Test Workflow ---
# def db_test_workflow_main(): # REMOVED
# ... function content removed ...


if __name__ == "__main__":
    # Keep the main guard but simplify invocation
    # The SLURM script will directly call this main function
    # No need for subcommand parsing here anymore
    main() 